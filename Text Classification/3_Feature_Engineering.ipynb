{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = \"Data/News_dataset.pickle\"\n",
    "\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/bbc\\business\\001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>1</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/bbc\\business\\002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>1</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/bbc\\business\\003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>1</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/bbc\\business\\004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>1</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/bbc\\business\\005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   File_Name  Category  \\\n",
       "0  Data/bbc\\business\\001.txt  business   \n",
       "1  Data/bbc\\business\\002.txt  business   \n",
       "2  Data/bbc\\business\\003.txt  business   \n",
       "3  Data/bbc\\business\\004.txt  business   \n",
       "4  Data/bbc\\business\\005.txt  business   \n",
       "\n",
       "                                             Content  id  News_length  \n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   1         2559  \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   1         2252  \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   1         1551  \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   1         2401  \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   1         1569  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dollar gains on Greenspan speech\\n\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\n\\nAnd Alan Greenspan highlighted the US government\\'s willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan\\'s speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman\\'s taking a much more sanguine view on the current account deficit than he\\'s taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He\\'s taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\\n\\nWorries about the deficit concerns about China do, however, remain. China\\'s currency remains pegged to the dollar and the US currency\\'s sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing\\'s policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve\\'s decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US\\'s yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\\n'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah langkah-langkah text cleaning dan preprocessing:\n",
    "1. Hapus karakter khusus '\\r', '\\n', '\"',\n",
    "2. Ubah ke bentuk lowercase\n",
    "3. Hapus sejumlah simbol\n",
    "4. Hapus 's, misal student's name\n",
    "5. Lematisasi, mengubah ke bentuk kata dasar dengan bantuan wordnet\n",
    "6. Hapus stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "punctuation_signs = list(\"?:!.,;\")\n",
    "df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove possessive pronouns\n",
    "df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading punkt and wordnet from NLTK\n",
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['Content_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_5'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Japan narrowly escapes recession\\n\\nJapan\\'s economy teetered on the brink of a technical recession in the three months to September, figures show.\\n\\nRevised figures indicated growth of just 0.1% - and a similar-sized contraction in the previous quarter. On an annual basis, the data suggests annual growth of just 0.2%, suggesting a much more hesitant recovery than had previously been thought. A common technical definition of a recession is two successive quarters of negative growth.\\n\\nThe government was keen to play down the worrying implications of the data. \"I maintain the view that Japan\\'s economy remains in a minor adjustment phase in an upward climb, and we will monitor developments carefully,\" said economy minister Heizo Takenaka. But in the face of the strengthening yen making exports less competitive and indications of weakening economic conditions ahead, observers were less sanguine. \"It\\'s painting a picture of a recovery... much patchier than previously thought,\" said Paul Sheard, economist at Lehman Brothers in Tokyo. Improvements in the job market apparently have yet to feed through to domestic demand, with private consumption up just 0.2% in the third quarter.\\n'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Japan narrowly escapes recession  Japan's economy teetered on the brink of a technical recession in the three months to September, figures show.  Revised figures indicated growth of just 0.1% - and a similar-sized contraction in the previous quarter. On an annual basis, the data suggests annual growth of just 0.2%, suggesting a much more hesitant recovery than had previously been thought. A common technical definition of a recession is two successive quarters of negative growth.  The government was keen to play down the worrying implications of the data. I maintain the view that Japan's economy remains in a minor adjustment phase in an upward climb, and we will monitor developments carefully, said economy minister Heizo Takenaka. But in the face of the strengthening yen making exports less competitive and indications of weakening economic conditions ahead, observers were less sanguine. It's painting a picture of a recovery... much patchier than previously thought, said Paul Sheard, economist at Lehman Brothers in Tokyo. Improvements in the job market apparently have yet to feed through to domestic demand, with private consumption up just 0.2% in the third quarter. \""
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"japan narrowly escapes recession  japan's economy teetered on the brink of a technical recession in the three months to september, figures show.  revised figures indicated growth of just 0.1% - and a similar-sized contraction in the previous quarter. on an annual basis, the data suggests annual growth of just 0.2%, suggesting a much more hesitant recovery than had previously been thought. a common technical definition of a recession is two successive quarters of negative growth.  the government was keen to play down the worrying implications of the data. i maintain the view that japan's economy remains in a minor adjustment phase in an upward climb, and we will monitor developments carefully, said economy minister heizo takenaka. but in the face of the strengthening yen making exports less competitive and indications of weakening economic conditions ahead, observers were less sanguine. it's painting a picture of a recovery... much patchier than previously thought, said paul sheard, economist at lehman brothers in tokyo. improvements in the job market apparently have yet to feed through to domestic demand, with private consumption up just 0.2% in the third quarter. \""
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"japan narrowly escapes recession  japan's economy teetered on the brink of a technical recession in the three months to september figures show  revised figures indicated growth of just 01% - and a similar-sized contraction in the previous quarter on an annual basis the data suggests annual growth of just 02% suggesting a much more hesitant recovery than had previously been thought a common technical definition of a recession is two successive quarters of negative growth  the government was keen to play down the worrying implications of the data i maintain the view that japan's economy remains in a minor adjustment phase in an upward climb and we will monitor developments carefully said economy minister heizo takenaka but in the face of the strengthening yen making exports less competitive and indications of weakening economic conditions ahead observers were less sanguine it's painting a picture of a recovery much patchier than previously thought said paul sheard economist at lehman brothers in tokyo improvements in the job market apparently have yet to feed through to domestic demand with private consumption up just 02% in the third quarter \""
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escapes recession  japan economy teetered on the brink of a technical recession in the three months to september figures show  revised figures indicated growth of just 01% - and a similar-sized contraction in the previous quarter on an annual basis the data suggests annual growth of just 02% suggesting a much more hesitant recovery than had previously been thought a common technical definition of a recession is two successive quarters of negative growth  the government was keen to play down the worrying implications of the data i maintain the view that japan economy remains in a minor adjustment phase in an upward climb and we will monitor developments carefully said economy minister heizo takenaka but in the face of the strengthening yen making exports less competitive and indications of weakening economic conditions ahead observers were less sanguine it painting a picture of a recovery much patchier than previously thought said paul sheard economist at lehman brothers in tokyo improvements in the job market apparently have yet to feed through to domestic demand with private consumption up just 02% in the third quarter '"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escape recession  japan economy teeter on the brink of a technical recession in the three months to september figure show  revise figure indicate growth of just 01% - and a similar-sized contraction in the previous quarter on an annual basis the data suggest annual growth of just 02% suggest a much more hesitant recovery than have previously be think a common technical definition of a recession be two successive quarter of negative growth  the government be keen to play down the worry implications of the data i maintain the view that japan economy remain in a minor adjustment phase in an upward climb and we will monitor developments carefully say economy minister heizo takenaka but in the face of the strengthen yen make export less competitive and indications of weaken economic condition ahead observers be less sanguine it paint a picture of a recovery much patchier than previously think say paul sheard economist at lehman brothers in tokyo improvements in the job market apparently have yet to fee through to domestic demand with private consumption up just 02% in the third quarter '"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escape recession  japan economy teeter   brink   technical recession   three months  september figure show  revise figure indicate growth   01% -   similar-sized contraction   previous quarter   annual basis  data suggest annual growth   02% suggest  much  hesitant recovery   previously  think  common technical definition   recession  two successive quarter  negative growth   government  keen  play   worry implications   data  maintain  view  japan economy remain   minor adjustment phase   upward climb    monitor developments carefully say economy minister heizo takenaka    face   strengthen yen make export less competitive  indications  weaken economic condition ahead observers  less sanguine  paint  picture   recovery much patchier  previously think say paul sheard economist  lehman brothers  tokyo improvements   job market apparently  yet  fee   domestic demand  private consumption   02%   third quarter '"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Content_Parsed_1</th>\n",
       "      <th>Content_Parsed_2</th>\n",
       "      <th>Content_Parsed_3</th>\n",
       "      <th>Content_Parsed_4</th>\n",
       "      <th>Content_Parsed_5</th>\n",
       "      <th>Content_Parsed_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/bbc\\business\\001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>1</td>\n",
       "      <td>2559</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   File_Name  Category  \\\n",
       "0  Data/bbc\\business\\001.txt  business   \n",
       "\n",
       "                                             Content  id  News_length  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   1         2559   \n",
       "\n",
       "                                    Content_Parsed_1  \\\n",
       "0  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_2  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_3  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_4  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_5  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_6  \n",
       "0  ad sales boost time warner profit  quarterly p...  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * variable task merupakan indikator eksekusi untuk soal 2 a,b,c *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "task = ''\n",
    "\n",
    "if task == 'a' :\n",
    "    # tanpa proses normalisasi\n",
    "    list_columns = [\"File_Name\", \"Category\", \"Content\", \"Content_Parsed_2\"]\n",
    "    df = df[list_columns]\n",
    "    df = df.rename(columns={'Content_Parsed_2': 'Content_Parsed'})\n",
    "\n",
    "elif task == 'b' :\n",
    "    # tanpa proses lemmatisation\n",
    "    df['Content_Parsed_b'] = df['Content_Parsed_4']\n",
    "    #proses menghilangkan stop word\n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        df['Content_Parsed_b'] = df['Content_Parsed_b'].str.replace(regex_stopword, '')\n",
    "\n",
    "    list_columns = [\"File_Name\", \"Category\", \"Content\", \"Content_Parsed_b\"]\n",
    "    df = df[list_columns]\n",
    "    df = df.rename(columns={'Content_Parsed_b': 'Content_Parsed'})\n",
    "\n",
    "elif task == 'c' :\n",
    "    # Tanpa menghilangkan stop word\n",
    "    list_columns = [\"File_Name\", \"Category\", \"Content\", \"Content_Parsed_5\"]\n",
    "    df = df[list_columns]\n",
    "    df = df.rename(columns={'Content_Parsed_5': 'Content_Parsed'})\n",
    "\n",
    "else :\n",
    "    #melakukan proses normalisasi\n",
    "    list_columns = [\"File_Name\", \"Category\", \"Content\", \"Content_Parsed_6\"]\n",
    "    df = df[list_columns]\n",
    "    df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/bbc\\business\\001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/bbc\\business\\002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>dollar gain  greenspan speech   dollar  hit  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/bbc\\business\\003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>yukos unit buyer face loan claim   owners  emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/bbc\\business\\004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>high fuel price hit ba profit  british airways...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/bbc\\business\\005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>pernod takeover talk lift domecq  share  uk dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data/bbc\\business\\006.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Japan narrowly escapes recession\\n\\nJapan's ec...</td>\n",
       "      <td>japan narrowly escape recession  japan economy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data/bbc\\business\\007.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Jobs growth still slow in the US\\n\\nThe US cre...</td>\n",
       "      <td>job growth still slow   us   us create fewer j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data/bbc\\business\\008.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>India calls for fair trade rules\\n\\nIndia, whi...</td>\n",
       "      <td>india call  fair trade rule  india  attend  g7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data/bbc\\business\\009.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ethiopia's crop production up 24%\\n\\nEthiopia ...</td>\n",
       "      <td>ethiopia crop production  24%  ethiopia produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data/bbc\\business\\010.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Court rejects $280bn tobacco case\\n\\nA US gove...</td>\n",
       "      <td>court reject $280bn tobacco case   us governme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   File_Name  Category  \\\n",
       "0  Data/bbc\\business\\001.txt  business   \n",
       "1  Data/bbc\\business\\002.txt  business   \n",
       "2  Data/bbc\\business\\003.txt  business   \n",
       "3  Data/bbc\\business\\004.txt  business   \n",
       "4  Data/bbc\\business\\005.txt  business   \n",
       "5  Data/bbc\\business\\006.txt  business   \n",
       "6  Data/bbc\\business\\007.txt  business   \n",
       "7  Data/bbc\\business\\008.txt  business   \n",
       "8  Data/bbc\\business\\009.txt  business   \n",
       "9  Data/bbc\\business\\010.txt  business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "5  Japan narrowly escapes recession\\n\\nJapan's ec...   \n",
       "6  Jobs growth still slow in the US\\n\\nThe US cre...   \n",
       "7  India calls for fair trade rules\\n\\nIndia, whi...   \n",
       "8  Ethiopia's crop production up 24%\\n\\nEthiopia ...   \n",
       "9  Court rejects $280bn tobacco case\\n\\nA US gove...   \n",
       "\n",
       "                                      Content_Parsed  \n",
       "0  ad sales boost time warner profit  quarterly p...  \n",
       "1  dollar gain  greenspan speech   dollar  hit  h...  \n",
       "2  yukos unit buyer face loan claim   owners  emb...  \n",
       "3  high fuel price hit ba profit  british airways...  \n",
       "4  pernod takeover talk lift domecq  share  uk dr...  \n",
       "5  japan narrowly escape recession  japan economy...  \n",
       "6  job growth still slow   us   us create fewer j...  \n",
       "7  india call  fair trade rule  india  attend  g7...  \n",
       "8  ethiopia crop production  24%  ethiopia produc...  \n",
       "9  court reject $280bn tobacco case   us governme...  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengubah nama kategori ke bentuk angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'business': 0,\n",
    "    'entertainment': 1,\n",
    "    'politics': 2,\n",
    "    'sport': 3,\n",
    "    'tech': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category mapping\n",
    "df['Category_Code'] = df['Category']\n",
    "df = df.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/bbc\\business\\001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/bbc\\business\\002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>dollar gain  greenspan speech   dollar  hit  h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/bbc\\business\\003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>yukos unit buyer face loan claim   owners  emb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/bbc\\business\\004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>high fuel price hit ba profit  british airways...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/bbc\\business\\005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>pernod takeover talk lift domecq  share  uk dr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   File_Name  Category  \\\n",
       "0  Data/bbc\\business\\001.txt  business   \n",
       "1  Data/bbc\\business\\002.txt  business   \n",
       "2  Data/bbc\\business\\003.txt  business   \n",
       "3  Data/bbc\\business\\004.txt  business   \n",
       "4  Data/bbc\\business\\005.txt  business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                      Content_Parsed  Category_Code  \n",
       "0  ad sales boost time warner profit  quarterly p...              0  \n",
       "1  dollar gain  greenspan speech   dollar  hit  h...              0  \n",
       "2  yukos unit buyer face loan claim   owners  emb...              0  \n",
       "3  high fuel price hit ba profit  british airways...              0  \n",
       "4  pernod takeover talk lift domecq  share  uk dr...              0  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari total data yang ada, kita ingin pisahkan ke dalam training data dan testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Content_Parsed'], \n",
    "                                                    df['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "1891\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300\n",
    "task3 = max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business' category:\n",
      "  . Most correlated unigrams:\n",
      ". market\n",
      ". price\n",
      ". economy\n",
      ". growth\n",
      ". bank\n",
      "  . Most correlated bigrams:\n",
      ". last year\n",
      ". year old\n",
      "\n",
      "# 'entertainment' category:\n",
      "  . Most correlated unigrams:\n",
      ". tv\n",
      ". music\n",
      ". star\n",
      ". award\n",
      ". film\n",
      "  . Most correlated bigrams:\n",
      ". mr blair\n",
      ". prime minister\n",
      "\n",
      "# 'politics' category:\n",
      "  . Most correlated unigrams:\n",
      ". minister\n",
      ". blair\n",
      ". party\n",
      ". election\n",
      ". labour\n",
      "  . Most correlated bigrams:\n",
      ". prime minister\n",
      ". mr blair\n",
      "\n",
      "# 'sport' category:\n",
      "  . Most correlated unigrams:\n",
      ". win\n",
      ". side\n",
      ". game\n",
      ". team\n",
      ". match\n",
      "  . Most correlated bigrams:\n",
      ". say mr\n",
      ". year old\n",
      "\n",
      "# 'tech' category:\n",
      "  . Most correlated unigrams:\n",
      ". digital\n",
      ". technology\n",
      ". computer\n",
      ". software\n",
      ". users\n",
      "  . Most correlated bigrams:\n",
      ". year old\n",
      ". say mr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('business', 0), ('entertainment', 1), ('politics', 2), ('sport', 3), ('tech', 4)])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_codes.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tell bbc', 'last year', 'prime minister', 'mr blair', 'year old', 'say mr']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "if task == 'a' :\n",
    "    # X_train\n",
    "    print(task)\n",
    "    with open('Data/X_train_a.pickle', 'wb') as output:\n",
    "        pickle.dump(X_train, output)\n",
    "\n",
    "    # X_test    \n",
    "    with open('Data/X_test_a.pickle', 'wb') as output:\n",
    "        pickle.dump(X_test, output)\n",
    "\n",
    "    # y_train\n",
    "    with open('Data/y_train_a.pickle', 'wb') as output:\n",
    "        pickle.dump(y_train, output)\n",
    "\n",
    "    # y_test\n",
    "    with open('Data/y_test_a.pickle', 'wb') as output:\n",
    "        pickle.dump(y_test, output)\n",
    "\n",
    "    # df\n",
    "    with open('Data/df_a.pickle', 'wb') as output:\n",
    "        pickle.dump(df, output)\n",
    "\n",
    "    # features_train\n",
    "    with open('Data/features_train_a.pickle', 'wb') as output:\n",
    "        pickle.dump(features_train, output)\n",
    "\n",
    "    # labels_train\n",
    "    with open('Data/labels_train_a.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_train, output)\n",
    "\n",
    "    # features_test\n",
    "    with open('Data/features_test_a.pickle', 'wb') as output:\n",
    "        pickle.dump(features_test, output)\n",
    "\n",
    "    # labels_test\n",
    "    with open('Data/labels_test_a.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_test, output)\n",
    "\n",
    "    # TF-IDF object\n",
    "    if task3 < 300 :\n",
    "        with open('Data/tfidf_a_2.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    elif task3 > 300 :\n",
    "        with open('Data/tfidf_a_4.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    else :\n",
    "        with open('Data/tfidf_a_3.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    \n",
    "elif task == 'b' :\n",
    "    print(task)\n",
    "    # X_train\n",
    "    with open('Data/X_train_b.pickle', 'wb') as output:\n",
    "        pickle.dump(X_train, output)\n",
    "\n",
    "    # X_test    \n",
    "    with open('Data/X_test_b.pickle', 'wb') as output:\n",
    "        pickle.dump(X_test, output)\n",
    "\n",
    "    # y_train\n",
    "    with open('Data/y_train_b.pickle', 'wb') as output:\n",
    "        pickle.dump(y_train, output)\n",
    "\n",
    "    # y_test\n",
    "    with open('Data/y_test_b.pickle', 'wb') as output:\n",
    "        pickle.dump(y_test, output)\n",
    "\n",
    "    # df\n",
    "    with open('Data/df_b.pickle', 'wb') as output:\n",
    "        pickle.dump(df, output)\n",
    "\n",
    "    # features_train\n",
    "    with open('Data/features_train_b.pickle', 'wb') as output:\n",
    "        pickle.dump(features_train, output)\n",
    "\n",
    "    # labels_train\n",
    "    with open('Data/labels_train_b.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_train, output)\n",
    "\n",
    "    # features_test\n",
    "    with open('Data/features_test_b.pickle', 'wb') as output:\n",
    "        pickle.dump(features_test, output)\n",
    "\n",
    "    # labels_test\n",
    "    with open('Data/labels_test_b.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_test, output)\n",
    "\n",
    "    # TF-IDF object\n",
    "    if task3 < 300 :\n",
    "        with open('Data/tfidf_b_2.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    elif task3 > 300 :\n",
    "        with open('Data/tfidf_b_4.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    else :\n",
    "        with open('Data/tfidf_b_3.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    \n",
    "elif task == 'c' :\n",
    "    print(task)\n",
    "    # X_train\n",
    "    with open('Data/X_train_c.pickle', 'wb') as output:\n",
    "        pickle.dump(X_train, output)\n",
    "\n",
    "    # X_test    \n",
    "    with open('Data/X_test_c.pickle', 'wb') as output:\n",
    "        pickle.dump(X_test, output)\n",
    "\n",
    "    # y_train\n",
    "    with open('Data/y_train_c.pickle', 'wb') as output:\n",
    "        pickle.dump(y_train, output)\n",
    "\n",
    "    # y_test\n",
    "    with open('Data/y_test_c.pickle', 'wb') as output:\n",
    "        pickle.dump(y_test, output)\n",
    "\n",
    "    # df\n",
    "    with open('Data/df_c.pickle', 'wb') as output:\n",
    "        pickle.dump(df, output)\n",
    "\n",
    "    # features_train\n",
    "    with open('Data/features_train_c.pickle', 'wb') as output:\n",
    "        pickle.dump(features_train, output)\n",
    "\n",
    "    # labels_train\n",
    "    with open('Data/labels_train_c.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_train, output)\n",
    "\n",
    "    # features_test\n",
    "    with open('Data/features_test_c.pickle', 'wb') as output:\n",
    "        pickle.dump(features_test, output)\n",
    "\n",
    "    # labels_test\n",
    "    with open('Data/labels_test_c.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_test, output)\n",
    "\n",
    "# TF-IDF object\n",
    "    if task3 < 300 :\n",
    "        with open('Data/tfidf_c_2.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    elif task3 > 300 :\n",
    "        with open('Data/tfidf_c_4.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    else :\n",
    "        with open('Data/tfidf_c_3.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    \n",
    "else :\n",
    "    # X_train\n",
    "    with open('Data/X_train.pickle', 'wb') as output:\n",
    "        pickle.dump(X_train, output)\n",
    "\n",
    "    # X_test    \n",
    "    with open('Data/X_test.pickle', 'wb') as output:\n",
    "        pickle.dump(X_test, output)\n",
    "\n",
    "    # y_train\n",
    "    with open('Data/y_train.pickle', 'wb') as output:\n",
    "        pickle.dump(y_train, output)\n",
    "\n",
    "    # y_test\n",
    "    with open('Data/y_test.pickle', 'wb') as output:\n",
    "        pickle.dump(y_test, output)\n",
    "\n",
    "    # df\n",
    "    with open('Data/df.pickle', 'wb') as output:\n",
    "        pickle.dump(df, output)\n",
    "\n",
    "    # features_train\n",
    "    with open('Data/features_train.pickle', 'wb') as output:\n",
    "        pickle.dump(features_train, output)\n",
    "\n",
    "    # labels_train\n",
    "    with open('Data/labels_train.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_train, output)\n",
    "\n",
    "    # features_test\n",
    "    with open('Data/features_test.pickle', 'wb') as output:\n",
    "        pickle.dump(features_test, output)\n",
    "\n",
    "    # labels_test\n",
    "    with open('Data/labels_test.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_test, output)\n",
    "\n",
    "# TF-IDF object\n",
    "    if task3 < 300 :\n",
    "        with open('Data/tfidf_2.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    elif task3 > 300 :\n",
    "        with open('Data/tfidf_4.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    else :\n",
    "        with open('Data/tfidf_3.pickle', 'wb') as output:\n",
    "            pickle.dump(tfidf, output)\n",
    "    \n",
    "print(task3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : nama file tfidf diatas menunjukan nilai tfidf yang digunakan. misalkan tfidf_2 = tfidf dgn nilai max_feature < 300. tfidf_4 = tfidf dengan nilai max_featur > 300"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
